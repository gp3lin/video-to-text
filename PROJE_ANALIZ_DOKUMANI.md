# Video-to-Text Projesi - DetaylÄ± Analiz ve DokÃ¼mantasyon

**Tarih:** 30 KasÄ±m 2025
**Proje Durumu:** Faz 2 TamamlandÄ± - Core ModÃ¼ller Ä°mplemente Edildi
**GeliÅŸtirme OrtamÄ±:** Python 3.x, Windows

---

## Ä°Ã§indekiler

1. [Proje Genel BakÄ±ÅŸ](#proje-genel-bakÄ±ÅŸ)
2. [KlasÃ¶r ve Dosya YapÄ±sÄ±](#klasÃ¶r-ve-dosya-yapÄ±sÄ±)
3. [ModÃ¼l BazlÄ± DetaylÄ± Analiz](#modÃ¼l-bazlÄ±-detaylÄ±-analiz)
4. [Veri AkÄ±ÅŸÄ± ve Mimari](#veri-akÄ±ÅŸÄ±-ve-mimari)
5. [KullanÄ±lan Teknolojiler](#kullanÄ±lan-teknolojiler)
6. [KonfigÃ¼rasyon Sistemi](#konfigÃ¼rasyon-sistemi)
7. [GÃ¼venlik ve Best Practices](#gÃ¼venlik-ve-best-practices)
8. [Eksik BileÅŸenler ve Sonraki AdÄ±mlar](#eksik-bileÅŸenler-ve-sonraki-adÄ±mlar)

---

## 1. Proje Genel BakÄ±ÅŸ

### AmaÃ§
Video dosyalarÄ±ndan konuÅŸmalarÄ± metne Ã§eviren ve konuÅŸmacÄ±lara gÃ¶re ayÄ±ran aÃ§Ä±k kaynak bir Python projesi.

### Temel Ã–zellikler
- âœ… **Video'dan Ses Ã‡Ä±karma**: FFmpeg kullanarak video dosyalarÄ±ndan ses extraction
- âœ… **KonuÅŸma TanÄ±ma (Speech-to-Text)**: OpenAI Whisper ile Ã§oklu dil desteÄŸi
- âœ… **KonuÅŸmacÄ± AyÄ±rma (Speaker Diarization)**: pyannote.audio ile kim-ne-zaman konuÅŸtu analizi
- âœ… **AkÄ±llÄ± BirleÅŸtirme**: Transcription ve diarization sonuÃ§larÄ±nÄ± overlap mantÄ±ÄŸÄ±yla birleÅŸtirme
- âœ… **Ã‡oklu Format DesteÄŸi**: JSON ve Text formatÄ±nda Ã§Ä±ktÄ±
- â³ **Web ArayÃ¼zÃ¼**: Streamlit (henÃ¼z implement edilmedi)
- â³ **CLI ArayÃ¼zÃ¼**: Komut satÄ±rÄ± arabirimi (kÄ±smi implement)

### KullanÄ±m SenaryolarÄ±
1. **RÃ¶portaj Transkriptleri**: Ä°ki veya daha fazla kiÅŸinin konuÅŸtuÄŸu rÃ¶portajlarÄ± metne Ã§evirme
2. **Podcast DÃ¶kÃ¼mantasyonu**: Podcast bÃ¶lÃ¼mlerini metin formatÄ±nda arÅŸivleme
3. **ToplantÄ± KayÄ±tlarÄ±**: Video toplantÄ±larÄ±nÄ±n metinlerini konuÅŸmacÄ±lara gÃ¶re ayÄ±rarak kaydetme
4. **EÄŸitim Ä°Ã§erikleri**: Ders videolarÄ±ndan not Ã§Ä±karma
5. **AraÅŸtÄ±rma**: SÃ¶zel iÃ§eriklerin nicel analizi iÃ§in veri hazÄ±rlama

---

## 2. KlasÃ¶r ve Dosya YapÄ±sÄ±

### Proje Dizin AÄŸacÄ±

```
video-to-text/
â”‚
â”œâ”€â”€ ğŸ“ app/                          # Ana uygulama modÃ¼lleri
â”‚   â”œâ”€â”€ __init__.py                  # Package tanÄ±mÄ± (boÅŸ)
â”‚   â”œâ”€â”€ video_processor.py           # Video/ses iÅŸleme (243 satÄ±r)
â”‚   â”œâ”€â”€ transcriber.py               # KonuÅŸma tanÄ±ma (336 satÄ±r)
â”‚   â”œâ”€â”€ diarizer.py                  # KonuÅŸmacÄ± ayÄ±rma (423 satÄ±r)
â”‚   â””â”€â”€ output_formatter.py          # Ã‡Ä±ktÄ± formatlama (452 satÄ±r)
â”‚
â”œâ”€â”€ ğŸ“ config/                       # KonfigÃ¼rasyon yÃ¶netimi
â”‚   â”œâ”€â”€ __init__.py                  # Package tanÄ±mÄ± (boÅŸ)
â”‚   â””â”€â”€ settings.py                  # TÃ¼m ayarlar (89 satÄ±r)
â”‚
â”œâ”€â”€ ğŸ“ uploads/                      # YÃ¼klenen video dosyalarÄ±
â”‚   â””â”€â”€ .gitkeep                     # (BoÅŸ klasÃ¶rÃ¼ Git'te tutmak iÃ§in)
â”‚
â”œâ”€â”€ ğŸ“ outputs/                      # Ãœretilen JSON/TXT dosyalarÄ±
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ ğŸ“ models/                       # Ä°ndirilen AI modelleri
â”‚   â””â”€â”€ .gitkeep                     # (Whisper ve pyannote modelleri buraya indirilir)
â”‚
â”œâ”€â”€ ğŸ“ logs/                         # Log dosyalarÄ±
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ ğŸ“ venv/                         # Python sanal ortamÄ± (Git'te yok)
â”‚
â”œâ”€â”€ ğŸ“ .git/                         # Git version control
â”‚
â”œâ”€â”€ ğŸ“ .claude/                      # Claude Code konfigÃ¼rasyonu
â”‚   â””â”€â”€ settings.local.json
â”‚
â”œâ”€â”€ ğŸ“„ v_to_t.py                     # Ana CLI programÄ± (18 satÄ±r - henÃ¼z iskelet)
â”œâ”€â”€ ğŸ“„ requirements.txt              # Python baÄŸÄ±mlÄ±lÄ±klarÄ± (24 satÄ±r)
â”œâ”€â”€ ğŸ“„ .env.example                  # Ã–rnek environment variables (16 satÄ±r)
â”œâ”€â”€ ğŸ“„ .gitignore                    # Git ignore kurallarÄ± (83 satÄ±r)
â””â”€â”€ ğŸ“„ README.md                     # Proje README (147 satÄ±r)
```

### Dosya BoyutlarÄ± ve KarmaÅŸÄ±klÄ±k

| ModÃ¼l | SatÄ±r SayÄ±sÄ± | Fonksiyon/SÄ±nÄ±f | KarmaÅŸÄ±klÄ±k |
|-------|-------------|----------------|------------|
| video_processor.py | 243 | 3 fonksiyon | Orta |
| transcriber.py | 336 | 1 sÄ±nÄ±f (6 metod) + 1 yardÄ±mcÄ± fonksiyon | YÃ¼ksek |
| diarizer.py | 423 | 1 sÄ±nÄ±f (5 metod) + 1 yardÄ±mcÄ± fonksiyon | YÃ¼ksek |
| output_formatter.py | 452 | 1 sÄ±nÄ±f (8 static metod) | YÃ¼ksek |
| settings.py | 89 | 0 (sadece konfigÃ¼rasyon) | DÃ¼ÅŸÃ¼k |
| **TOPLAM** | **1,543** | **3 sÄ±nÄ±f, 22 metod/fonksiyon** | - |

---

## 3. ModÃ¼l BazlÄ± DetaylÄ± Analiz

### 3.1. config/settings.py

**AmaÃ§:** Merkezi konfigÃ¼rasyon yÃ¶netimi

**Sorumluluklar:**
- Environment variables yÃ¶netimi (.env dosyasÄ±ndan)
- KlasÃ¶r yollarÄ± tanÄ±mlama ve oluÅŸturma
- Model parametreleri
- Ses iÅŸleme ayarlarÄ±
- Logging konfigÃ¼rasyonu

**Ã–nemli DeÄŸiÅŸkenler:**

```python
# KlasÃ¶r YollarÄ± (pathlib.Path nesneleri)
BASE_DIR = Path(__file__).parent.parent.resolve()
UPLOAD_DIR = BASE_DIR / "uploads"
OUTPUT_DIR = BASE_DIR / "outputs"
MODEL_DIR = BASE_DIR / "models"
LOG_DIR = BASE_DIR / "logs"

# Whisper AyarlarÄ±
WHISPER_MODEL_SIZE = "small"  # tiny, base, small, medium, large
WHISPER_LANGUAGE = "tr"       # tr, en, vb.

# Pyannote AyarlarÄ±
HUGGINGFACE_TOKEN = ""        # .env'den okunur (GÄ°ZLÄ°)

# Ses Ä°ÅŸleme
AUDIO_SAMPLE_RATE = 16000     # 16 kHz (konuÅŸma iÃ§in optimal)
AUDIO_CHANNELS = 1            # Mono

# Limitler
MAX_FILE_SIZE_MB = 500
```

**TasarÄ±m KararlarÄ±:**
1. âœ… **pathlib.Path kullanÄ±mÄ±**: Platform baÄŸÄ±msÄ±z yol yÃ¶netimi (Windows/Linux/Mac)
2. âœ… **Otomatik klasÃ¶r oluÅŸturma**: `directory.mkdir(exist_ok=True)` ile
3. âœ… **Environment variables**: Gizli bilgiler (token) .env dosyasÄ±nda
4. âœ… **Type hints yok**: Basit konfigÃ¼rasyon, type gerekmiyor
5. âœ… **Default deÄŸerler**: `os.getenv("KEY", "default")` ile fallback

**Ä°yileÅŸtirme Ã–nerileri:**
- âš ï¸ Dataclass veya Pydantic kullanarak tip gÃ¼venliÄŸi eklenebilir
- âš ï¸ Validation logic eklenebilir (Ã¶rn: MAX_FILE_SIZE_MB > 0)

---

### 3.2. app/video_processor.py

**AmaÃ§:** Video dosyalarÄ±ndan ses Ã§Ä±karma ve Ã¶n iÅŸleme

**Fonksiyonlar:**

#### 1. `extract_audio_from_video(video_path, output_path=None) -> Path`

**Ne Yapar:**
- Video dosyasÄ±ndan ses kanalÄ±nÄ± Ã§Ä±karÄ±r
- WAV formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r
- 16 kHz sample rate, mono kanal ayarlar

**KullanÄ±lan KÃ¼tÃ¼phaneler:**
- `moviepy.editor.VideoFileClip`: Video yÃ¼kleme
- FFmpeg (arka planda): Ses kodlama

**Ä°ÅŸ AkÄ±ÅŸÄ±:**
```
Video DosyasÄ±
    â†“
Video yÃ¼kleme (VideoFileClip)
    â†“
Ses kanalÄ±nÄ± al (.audio)
    â†“
WAV formatÄ±nda kaydet (write_audiofile)
    â”œâ”€â”€ Sample rate: 16 kHz
    â”œâ”€â”€ Codec: pcm_s16le (16-bit PCM)
    â”œâ”€â”€ Kanal: Mono (1 kanal)
    â””â”€â”€ FFmpeg parametreleri: -ac 1
    â†“
KaynaklarÄ± temizle (close)
    â†“
Ses DosyasÄ± (WAV)
```

**Hata YÃ¶netimi:**
- âœ… Dosya bulunamadÄ± kontrolÃ¼
- âœ… Video'da ses yoksa hata
- âœ… YarÄ±m kalmÄ±ÅŸ dosya silme (exception durumunda)
- âœ… DetaylÄ± loglama (loguru)

**Ã–rnek KullanÄ±m:**
```python
audio_path = extract_audio_from_video("video.mp4")
# Ã‡Ä±ktÄ±: uploads/video_audio.wav
```

#### 2. `get_audio_duration(audio_path) -> float`

**Ne Yapar:**
- Ses dosyasÄ±nÄ±n sÃ¼resini saniye cinsinden dÃ¶ndÃ¼rÃ¼r

**KullanÄ±m:**
```python
duration = get_audio_duration("audio.wav")
# Ã‡Ä±ktÄ±: 125.50 (saniye)
```

#### 3. `validate_video_file(video_path) -> bool`

**Ne Yapar:**
- Video dosyasÄ±nÄ± doÄŸrular (var mÄ±, format destekleniyor mu, boyut uygun mu)

**Kontroller:**
- âœ… Dosya varlÄ±ÄŸÄ±
- âœ… Format kontrolÃ¼ (`.mp4`, `.avi`, `.mov`, `.mkv`, `.webm`)
- âœ… Boyut limiti (MAX_FILE_SIZE_MB)

**TasarÄ±m Kalitesi:**
- âœ… **Separation of Concerns**: Her fonksiyon tek bir iÅŸ yapÄ±yor
- âœ… **Type hints**: Parametreler ve dÃ¶nÃ¼ÅŸ deÄŸerleri belirtilmiÅŸ
- âœ… **Docstrings**: Her fonksiyon detaylÄ± dokÃ¼mante edilmiÅŸ
- âœ… **Error handling**: Try-except bloklarÄ± ve temizlik
- âœ… **Logging**: Her adÄ±m loglanÄ±yor (debug, info, error, success)
- âœ… **Resource management**: Video/audio nesneleri dÃ¼zgÃ¼n kapatÄ±lÄ±yor

---

### 3.3. app/transcriber.py

**AmaÃ§:** Ses dosyalarÄ±nÄ± metne Ã§evirme (Speech-to-Text)

**Ana SÄ±nÄ±f: `Transcriber`**

#### SÄ±nÄ±f YapÄ±sÄ±

```python
class Transcriber:
    def __init__(self, model_size=None, language=None)
    def load_model(self)
    def transcribe(self, audio_path, **kwargs) -> Dict
    def _process_result(self, raw_result) -> Dict
    def _calculate_confidence(self, segment) -> float
    def transcribe_with_progress(self, audio_path, **kwargs) -> Dict
```

#### Model YÃ¶netimi

**Whisper Model BoyutlarÄ±:**
| Boyut | Dosya | HÄ±z | DoÄŸruluk | KullanÄ±m |
|-------|-------|-----|----------|----------|
| tiny | 39 MB | En hÄ±zlÄ± | DÃ¼ÅŸÃ¼k | Test |
| base | 74 MB | HÄ±zlÄ± | Orta | HÄ±zlÄ± iÅŸler |
| small | 244 MB | Orta | Ä°yi | **Ã–NERÄ°LEN** |
| medium | 769 MB | YavaÅŸ | Ã‡ok Ä°yi | YÃ¼ksek doÄŸruluk |
| large | 1550 MB | En yavaÅŸ | En Ä°yi | Kritik iÅŸler |

**Model YÃ¼kleme:**
```python
def load_model(self):
    self.model = whisper.load_model(
        self.model_size,
        download_root=str(settings.MODEL_DIR)
    )
```

- Ä°lk kullanÄ±mda model internet Ã¼zerinden indirilir (~/.cache/whisper/)
- Sonraki kullanÄ±mlarda cache'den yÃ¼klenir (hÄ±zlÄ±)
- Lazy loading: Model sadece gerektiÄŸinde yÃ¼klenir

#### Transcription Ä°ÅŸlemi

**Ana Fonksiyon:**
```python
def transcribe(self, audio_path, **kwargs) -> Dict:
    result = self.model.transcribe(
        str(audio_path),
        language=self.language,
        verbose=False,
        **kwargs
    )
    return self._process_result(result)
```

**Whisper Ã‡Ä±ktÄ±sÄ± (Ham):**
```python
{
    "text": "Tam metin...",
    "segments": [
        {
            "id": 0,
            "start": 0.0,
            "end": 3.5,
            "text": " Merhaba",
            "avg_logprob": -0.15,
            "no_speech_prob": 0.05
        }
    ],
    "language": "tr"
}
```

**Ä°ÅŸlenmiÅŸ Ã‡Ä±ktÄ±:**
```python
{
    "text": "Tam metin...",
    "segments": [
        {
            "id": 0,
            "start": 0.0,
            "end": 3.5,
            "text": "Merhaba",  # strip() uygulanmÄ±ÅŸ
            "confidence": 0.95  # HesaplanmÄ±ÅŸ gÃ¼ven skoru
        }
    ],
    "language": "tr"
}
```

#### GÃ¼ven Skoru Hesaplama

**Algoritma:**
```python
def _calculate_confidence(self, segment) -> float:
    avg_logprob = segment.get("avg_logprob", -1.0)
    no_speech_prob = segment.get("no_speech_prob", 0.0)

    # avg_logprob'a gÃ¶re base confidence
    if avg_logprob > -0.5:
        base_confidence = 0.95
    elif avg_logprob > -1.0:
        base_confidence = 0.85
    elif avg_logprob > -1.5:
        base_confidence = 0.75
    else:
        base_confidence = 0.65

    # Sessizlik olasÄ±lÄ±ÄŸÄ±yla azalt
    confidence = base_confidence * (1 - no_speech_prob)

    return max(0.0, min(1.0, confidence))
```

**Neden Gerekli:**
- Whisper doÄŸrudan confidence skoru vermez
- `avg_logprob` ve `no_speech_prob` kullanarak yaklaÅŸÄ±k hesaplama
- KullanÄ±cÄ±ya sonuÃ§larÄ±n gÃ¼venilirliÄŸi hakkÄ±nda bilgi

**TasarÄ±m Kalitesi:**
- âœ… **OOP tasarÄ±m**: Model yÃ¶netimi iÃ§in sÄ±nÄ±f kullanÄ±mÄ±
- âœ… **Lazy loading**: Model sadece gerektiÄŸinde yÃ¼klenir
- âœ… **Encapsulation**: Private metodlar (_process_result, _calculate_confidence)
- âœ… **Flexibility**: **kwargs ile ekstra parametre desteÄŸi
- âœ… **Progress tracking**: Ä°steÄŸe baÄŸlÄ± ilerleme Ã§ubuÄŸu

---

### 3.4. app/diarizer.py

**AmaÃ§:** KonuÅŸmacÄ±larÄ± ayÄ±rma ve kim-ne-zaman konuÅŸtu analizi

**Ana SÄ±nÄ±f: `SpeakerDiarizer`**

#### SÄ±nÄ±f YapÄ±sÄ±

```python
class SpeakerDiarizer:
    def __init__(self, hf_token=None, device="auto")
    def load_model(self)
    def diarize(self, audio_path, num_speakers=None, ...) -> List[Dict]
    def _process_diarization(self, diarization) -> List[Dict]
    def get_speaker_statistics(self, segments) -> Dict
```

#### pyannote.audio Pipeline

**Model:**
- `pyannote/speaker-diarization-3.1` (Hugging Face'de hosted)
- ~300 MB boyutunda
- Hugging Face token gerektirir (Ã¼cretsiz hesap)

**Token GerekliliÄŸi:**
```python
# .env dosyasÄ±nda
HUGGINGFACE_TOKEN=hf_xxxxxxxxxxxxx

# settings.py'de
HUGGINGFACE_TOKEN = os.getenv("HUGGINGFACE_TOKEN", "")
```

**Token Alma:**
1. https://huggingface.co/ â†’ Hesap oluÅŸtur
2. Settings â†’ Access Tokens
3. New token (Read yetkisi yeterli)
4. Token'Ä± `.env` dosyasÄ±na ekle

#### GPU vs CPU

**Device YÃ¶netimi:**
```python
def __init__(self, hf_token=None, device="auto"):
    if device == "auto":
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
    else:
        self.device = device
```

**Performans FarkÄ±:**
| Cihaz | 10 dakikalÄ±k ses | HÄ±z |
|-------|------------------|-----|
| CPU (i7) | ~8-10 dakika | 1x |
| GPU (NVIDIA) | ~1-2 dakika | 5-8x |

**GPU Kurulumu (Windows):**
```bash
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

#### Diarization Ä°ÅŸlemi

**Ana Fonksiyon:**
```python
def diarize(self, audio_path, num_speakers=None,
            min_speakers=None, max_speakers=None) -> List[Dict]:

    params = {}
    if num_speakers is not None:
        params["num_speakers"] = num_speakers
    else:
        if min_speakers is not None:
            params["min_speakers"] = min_speakers
        if max_speakers is not None:
            params["max_speakers"] = max_speakers

    diarization = self.pipeline(str(audio_path), **params)
    segments = self._process_diarization(diarization)
    return segments
```

**KullanÄ±m SenaryolarÄ±:**

1. **KonuÅŸmacÄ± sayÄ±sÄ± biliniyor:**
```python
segments = diarizer.diarize("audio.wav", num_speakers=2)
```

2. **AralÄ±k biliniyor:**
```python
segments = diarizer.diarize("audio.wav", min_speakers=2, max_speakers=5)
```

3. **Otomatik tespit:**
```python
segments = diarizer.diarize("audio.wav")  # pyannote otomatik belirler
```

**Ã‡Ä±ktÄ± FormatÄ±:**
```python
[
    {
        "speaker": "SPEAKER_00",
        "start": 0.0,
        "end": 15.5,
        "duration": 15.5
    },
    {
        "speaker": "SPEAKER_01",
        "start": 15.5,
        "end": 32.1,
        "duration": 16.6
    },
    ...
]
```

**Not:** pyannote konuÅŸmacÄ± isimlerini bilmez, sadece `SPEAKER_00`, `SPEAKER_01` gibi etiketler verir.

#### Ä°statistik Hesaplama

**Fonksiyon:**
```python
def get_speaker_statistics(self, segments) -> Dict:
    # Her konuÅŸmacÄ± iÃ§in:
    # - Toplam konuÅŸma sÃ¼resi
    # - KaÃ§ kez konuÅŸtu
    # - Ortalama segment sÃ¼resi
    # - YÃ¼zde oranÄ±
```

**Ã–rnek Ã‡Ä±ktÄ±:**
```python
{
    "SPEAKER_00": {
        "total_duration": 125.5,
        "num_segments": 10,
        "avg_segment_duration": 12.55,
        "percentage": 45.2
    },
    "SPEAKER_01": {
        "total_duration": 152.0,
        "num_segments": 12,
        "avg_segment_duration": 12.67,
        "percentage": 54.8
    }
}
```

**KullanÄ±m:**
```python
segments = diarizer.diarize("audio.wav")
stats = diarizer.get_speaker_statistics(segments)
print(f"SPEAKER_00: %{stats['SPEAKER_00']['percentage']}")
```

**TasarÄ±m Kalitesi:**
- âœ… **Token validation**: Token yoksa aÃ§Ä±klayÄ±cÄ± hata mesajÄ±
- âœ… **Device flexibility**: Auto/manual GPU/CPU seÃ§imi
- âœ… **Speaker flexibility**: num_speakers veya min/max aralÄ±ÄŸÄ±
- âœ… **Sorted output**: Segmentler zaman sÄ±rasÄ±na gÃ¶re
- âœ… **Statistics**: KullanÄ±ÅŸlÄ± istatistik hesaplama

---

### 3.5. app/output_formatter.py

**AmaÃ§:** Transcription ve diarization sonuÃ§larÄ±nÄ± birleÅŸtirme ve formatlama

**Ana SÄ±nÄ±f: `OutputFormatter` (TÃ¼m metodlar static)**

#### Neden Static Metodlar?

```python
class OutputFormatter:
    @staticmethod
    def merge_results(...): ...

    @staticmethod
    def save_to_json(...): ...
```

**AvantajlarÄ±:**
- State tutmaya gerek yok (instance variable yok)
- Utility class olarak kullanÄ±m
- `OutputFormatter.merge_results()` ÅŸeklinde direkt Ã§aÄŸrÄ±
- Test etmesi kolay

#### Ana Fonksiyonlar

**1. merge_results() - En Kritik Fonksiyon**

**Sorun:**
- Transcription: "0.0-3.5s arasÄ±: 'Merhaba bugÃ¼n...'"
- Diarization: "0.0-15.5s arasÄ±: SPEAKER_00 konuÅŸuyor"
- **Zaman aralÄ±klarÄ± tam Ã¶rtÃ¼ÅŸmÃ¼yor!**

**Ã‡Ã¶zÃ¼m: Overlap (Ã–rtÃ¼ÅŸme) MantÄ±ÄŸÄ±**

```python
def _find_speaker_for_segment(start, end, diarization) -> str:
    max_overlap = 0
    best_speaker = "SPEAKER_UNKNOWN"

    for dia_seg in diarization:
        # Ã–rtÃ¼ÅŸme hesapla
        overlap_start = max(start, dia_seg["start"])
        overlap_end = min(end, dia_seg["end"])
        overlap = max(0, overlap_end - overlap_start)

        # En Ã§ok Ã¶rtÃ¼ÅŸeni bul
        if overlap > max_overlap:
            max_overlap = overlap
            best_speaker = dia_seg["speaker"]

    return best_speaker
```

**GÃ¶rsel Ã–rnek:**
```
Transcription:     [----Segment 1----]
                   0.0              3.5

Diarization:    [--------SPEAKER_00--------]
                0.0                      15.5

Overlap:           [----3.5s----]
                   0.0          3.5

SonuÃ§: Segment 1 â†’ SPEAKER_00 (3.5s overlap)
```

**Edge Case: Ã–rtÃ¼ÅŸme Yoksa**

```python
# Ã–rtÃ¼ÅŸme yoksa en yakÄ±n konuÅŸmacÄ±yÄ± bul
if max_overlap == 0:
    min_distance = float('inf')
    for dia_seg in diarization:
        distance = min(
            abs(start - dia_seg["start"]),
            abs(end - dia_seg["end"])
        )
        if distance < min_distance:
            min_distance = distance
            best_speaker = dia_seg["speaker"]
```

**2. _group_by_speaker() - Ä°statistik**

```python
def _group_by_speaker(merged_segments, diarization) -> Dict:
    speakers = {}

    for seg in merged_segments:
        speaker = seg["speaker"]

        # Ä°lk kez gÃ¶rÃ¼lÃ¼yor
        if speaker not in speakers:
            speakers[speaker] = {
                "total_duration": 0,
                "total_words": 0,
                "num_segments": 0,
                "segments": []
            }

        # Ekle ve hesapla
        speakers[speaker]["segments"].append(seg)
        speakers[speaker]["total_duration"] += seg["duration"]
        speakers[speaker]["num_segments"] += 1
        speakers[speaker]["total_words"] += len(seg["text"].split())

    # YÃ¼zde hesapla
    total_duration = merged_segments[-1]["end"] if merged_segments else 0
    for speaker, data in speakers.items():
        data["percentage"] = round(
            (data["total_duration"] / total_duration) * 100, 1
        )

    return speakers
```

**3. save_to_json() - JSON Kaydetme**

```python
def save_to_json(result, output_path, pretty=True) -> Path:
    with open(output_path, 'w', encoding='utf-8') as f:
        if pretty:
            json.dump(
                result,
                f,
                indent=2,              # 2 boÅŸluk girintili
                ensure_ascii=False,   # TÃ¼rkÃ§e karakterler korunur
                sort_keys=False       # Metadata Ã¼stte kalsÄ±n
            )
        else:
            json.dump(result, f, ensure_ascii=False)
```

**ensure_ascii=False Ã–nemi:**
```python
# ensure_ascii=True (default)
{"text": "Merhaba d\\u00fcnya"}

# ensure_ascii=False
{"text": "Merhaba dÃ¼nya"}
```

**4. export_to_text() - Okunabilir Metin**

**Ã‡Ä±ktÄ± FormatÄ±:**
```
Video: example.mp4
SÃ¼re: 125.5s
Dil: tr
KonuÅŸmacÄ± SayÄ±sÄ±: 2
Ä°ÅŸlenme ZamanÄ±: 2025-11-30T16:30:45.123456

============================================================
ZAMAN Ã‡Ä°ZELGESÄ°
============================================================

[0.00s - 3.50s] SPEAKER_00:
  Merhaba, bugÃ¼n sizlere yeni projemizi anlatacaÄŸÄ±m.

[3.50s - 15.20s] SPEAKER_01:
  Ã‡ok gÃ¼zel, merak ettim. DetaylarÄ± dinleyelim.

============================================================
KONUÅMACI Ä°STATÄ°STÄ°KLERÄ°
============================================================

SPEAKER_00:
  Toplam SÃ¼re: 65.2s
  Kelime SayÄ±sÄ±: 450
  Segment SayÄ±sÄ±: 10
  YÃ¼zde: %45.2

SPEAKER_01:
  Toplam SÃ¼re: 60.3s
  Kelime SayÄ±sÄ±: 420
  Segment SayÄ±sÄ±: 8
  YÃ¼zde: %54.8

============================================================
TAM METÄ°N
============================================================

Merhaba, bugÃ¼n sizlere yeni projemizi anlatacaÄŸÄ±m...
```

**Final JSON YapÄ±sÄ±:**

```json
{
  "metadata": {
    "video_name": "example.mp4",
    "duration_seconds": 125.5,
    "language": "tr",
    "num_speakers": 2,
    "num_segments": 18,
    "processed_at": "2025-11-30T16:30:45.123456",
    "model_info": {
      "transcription": "OpenAI Whisper",
      "diarization": "pyannote.audio 3.1"
    }
  },
  "speakers": {
    "SPEAKER_00": {
      "total_duration": 65.2,
      "total_words": 450,
      "num_segments": 10,
      "percentage": 45.2,
      "segments": [...]
    },
    "SPEAKER_01": { ... }
  },
  "timeline": [
    {
      "start": 0.0,
      "end": 3.5,
      "duration": 3.5,
      "speaker": "SPEAKER_00",
      "text": "Merhaba, bugÃ¼n sizlere...",
      "confidence": 0.95
    },
    ...
  ],
  "full_transcript": "Tam metin..."
}
```

**TasarÄ±m Kalitesi:**
- âœ… **AkÄ±llÄ± eÅŸleÅŸtirme**: Overlap mantÄ±ÄŸÄ± ile robust birleÅŸtirme
- âœ… **Edge case handling**: Ã–rtÃ¼ÅŸme yoksa fallback
- âœ… **KapsamlÄ± istatistikler**: KonuÅŸmacÄ± bazlÄ± detaylÄ± analiz
- âœ… **Ã‡oklu format**: JSON ve Text export
- âœ… **TÃ¼rkÃ§e desteÄŸi**: ensure_ascii=False ile karakter korunumu
- âœ… **Metadata**: Ä°ÅŸlem bilgileri, model bilgileri

---

## 4. Veri AkÄ±ÅŸÄ± ve Mimari

### 4.1. Genel Ä°ÅŸ AkÄ±ÅŸÄ± (Pipeline)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Video DosyasÄ±  â”‚
â”‚    (MP4, AVI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   1. VIDEO PROCESSOR            â”‚
â”‚   video_processor.py            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Ses Ã§Ä±karma (extract_audio)  â”‚
â”‚  â€¢ WAV formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rme     â”‚
â”‚  â€¢ 16kHz, Mono ayarlama         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ WAV    â”‚
    â”‚ DosyasÄ±â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚                        â”‚
        â–¼                       â–¼                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  2A. TRANSCRIBER â”‚    â”‚  2B. DIARIZER    â”‚           â”‚
â”‚  transcriber.py  â”‚    â”‚  diarizer.py     â”‚           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚ â€¢ Whisper model  â”‚    â”‚ â€¢ pyannote model â”‚           â”‚
â”‚ â€¢ Ses â†’ Metin    â”‚    â”‚ â€¢ KonuÅŸmacÄ± ayÄ±r â”‚           â”‚
â”‚ â€¢ Zaman damgasÄ±  â”‚    â”‚ â€¢ Zaman damgasÄ±  â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
         â”‚                       â”‚                      â”‚
         â”‚                       â”‚                      â”‚
         â–¼                       â–¼                      â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
   â”‚Transcriptâ”‚          â”‚  Diarization â”‚              â”‚
   â”‚  Result  â”‚          â”‚    Result    â”‚              â”‚
   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
         â”‚                      â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
                    â–¼                                   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
         â”‚ 3. OUTPUT FORMATTER   â”‚                     â”‚
         â”‚ output_formatter.py   â”‚                     â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                     â”‚
         â”‚ â€¢ SonuÃ§larÄ± birleÅŸtir â”‚                     â”‚
         â”‚ â€¢ Overlap hesapla     â”‚                     â”‚
         â”‚ â€¢ Ä°statistik oluÅŸtur  â”‚                     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
                    â”‚                                   â”‚
                    â–¼                                   â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
         â”‚   Final Result      â”‚                       â”‚
         â”‚   (JSON + Text)     â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
                    â”‚                                   â”‚
              â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                            â”‚
              â”‚           â”‚                             â”‚
              â–¼           â–¼                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
         â”‚  JSON  â”‚  â”‚  TXT   â”‚                        â”‚
         â”‚ output â”‚  â”‚ output â”‚                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
                                                        â”‚
                                                        â–¼
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚ 4. WEB UI      â”‚
                                               â”‚ (Gelecek)      â”‚
                                               â”‚ Streamlit      â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2. Paralel Ä°ÅŸlem FÄ±rsatÄ±

**Mevcut Durum:**
```python
# SÄ±ralÄ± iÅŸlem (sequential)
audio = extract_audio(video)
transcription = transcriber.transcribe(audio)  # 3 dakika
diarization = diarizer.diarize(audio)          # 2 dakika
# Toplam: 5 dakika
```

**Ä°yileÅŸtirme (Threading/Multiprocessing):**
```python
# Paralel iÅŸlem
import concurrent.futures

audio = extract_audio(video)

with concurrent.futures.ThreadPoolExecutor() as executor:
    future_trans = executor.submit(transcriber.transcribe, audio)
    future_diar = executor.submit(diarizer.diarize, audio)

    transcription = future_trans.result()  # 3 dakika
    diarization = future_diar.result()     # 3 dakika (paralel)
# Toplam: 3 dakika (max(3, 2))
```

**Performans KazancÄ±:** %40

### 4.3. Mimari Prensipler

#### Separation of Concerns (SoC)

| ModÃ¼l | Sorumluluk | BaÄŸÄ±mlÄ±lÄ±k |
|-------|-----------|-----------|
| video_processor | Sadece video/ses iÅŸleme | moviepy, FFmpeg |
| transcriber | Sadece sesâ†’metin | Whisper |
| diarizer | Sadece konuÅŸmacÄ± ayÄ±rma | pyannote |
| output_formatter | Sadece formatlama | json, datetime |
| settings | Sadece konfigÃ¼rasyon | dotenv, os |

**AvantajlarÄ±:**
- âœ… Bir modÃ¼l deÄŸiÅŸtiÄŸinde diÄŸerleri etkilenmiyor
- âœ… Test edilebilirlik yÃ¼ksek
- âœ… Kod tekrarÄ± minimal

#### Single Responsibility Principle (SRP)

**Ã–rnek: video_processor.py**
- âœ… `extract_audio_from_video()`: Sadece ses Ã§Ä±karma
- âœ… `get_audio_duration()`: Sadece sÃ¼re hesaplama
- âœ… `validate_video_file()`: Sadece validasyon

**KÃ¶tÃ¼ TasarÄ±m OlsaydÄ±:**
```python
# âŒ KÃ¶tÃ¼: Her ÅŸeyi yapan dev fonksiyon
def process_video_and_transcribe_and_save(video_path):
    # Ses Ã§Ä±kar
    # Metne Ã§evir
    # KonuÅŸmacÄ± ayÄ±r
    # Kaydet
    # ...
```

#### Dependency Injection

**Ã–rnek:**
```python
class Transcriber:
    def __init__(self, model_size=None, language=None):
        # settings'ten deÄŸil, parametre olarak alÄ±yor
        self.model_size = model_size or settings.WHISPER_MODEL_SIZE
```

**Avantaj:** Test sÄ±rasÄ±nda farklÄ± deÄŸerler inject edebilirsiniz:
```python
# Production
transcriber = Transcriber()  # settings'ten alÄ±r

# Test
transcriber = Transcriber(model_size="tiny", language="en")
```

#### Error Handling Stratejisi

**KatmanlÄ± Hata YÃ¶netimi:**

1. **Validation Layer (En DÄ±ÅŸta):**
```python
def validate_video_file(video_path):
    if not video_path.exists():
        raise FileNotFoundError(...)
    if not is_supported_format():
        raise ValueError(...)
```

2. **Processing Layer (Ä°Ã§eride):**
```python
def extract_audio(video_path):
    try:
        video = VideoFileClip(...)
        audio.write_audiofile(...)
    except Exception as e:
        logger.error(...)
        # Temizlik
        if output_path.exists():
            output_path.unlink()
        raise  # HatayÄ± yukarÄ± fÄ±rlat
```

3. **User Layer (En DÄ±ÅŸta - CLI/Web):**
```python
try:
    result = process_video(video_path)
except FileNotFoundError as e:
    print(f"Video bulunamadÄ±: {e}")
except ValueError as e:
    print(f"GeÃ§ersiz format: {e}")
except Exception as e:
    print(f"Beklenmeyen hata: {e}")
```

**Prensip:** Low-level modÃ¼ller hata fÄ±rlatÄ±r, high-level modÃ¼ller yakalar ve kullanÄ±cÄ±ya bildirir.

---

## 5. KullanÄ±lan Teknolojiler

### 5.1. Ana KÃ¼tÃ¼phaneler

#### Video/Ses Ä°ÅŸleme

**1. moviepy (v1.x)**
- **KullanÄ±m:** Video dosyalarÄ±ndan ses Ã§Ä±karma
- **Backend:** FFmpeg (arka planda)
- **AvantajlarÄ±:**
  - âœ… Pythonic API
  - âœ… Ã‡ok sayÄ±da format desteÄŸi
  - âœ… Ses iÅŸleme parametrelerine kolay eriÅŸim
- **DezavantajlarÄ±:**
  - âš ï¸ BÃ¼yÃ¼k videolarda yavaÅŸ olabilir
  - âš ï¸ Bellek kullanÄ±mÄ± yÃ¼ksek

**Alternatif:**
```python
# Direkt FFmpeg kullanÄ±mÄ± (daha hÄ±zlÄ± ama low-level)
import subprocess
subprocess.run([
    "ffmpeg", "-i", "video.mp4",
    "-vn", "-acodec", "pcm_s16le",
    "-ar", "16000", "-ac", "1", "audio.wav"
])
```

**2. pydub**
- **KullanÄ±m:** Ses formatÄ± dÃ¶nÃ¼ÅŸÃ¼mleri (ÅŸu an aktif kullanÄ±lmÄ±yor)
- **Potansiyel kullanÄ±m:** MP3 â†’ WAV, ses normalizasyonu

#### AI/ML Modelleri

**3. openai-whisper**
- **Versiyon:** En son (GitHub'dan)
- **Model Mimarisi:** Transformer (Encoder-Decoder)
- **EÄŸitim Verisi:** 680,000 saat Ã§ok dilli veri
- **Dil DesteÄŸi:** 99 dil (TÃ¼rkÃ§e dahil)
- **Lisans:** MIT (Ãœcretsiz, ticari kullanÄ±m OK)

**Ã–zellikler:**
- âœ… Offline Ã§alÄ±ÅŸÄ±r (internet gerekmez)
- âœ… YÃ¼ksek doÄŸruluk (Ã¶zellikle medium/large)
- âœ… Zaman damgalÄ± Ã§Ä±ktÄ± (word-level)
- âœ… Dil otomatik algÄ±lama
- âš ï¸ GPU olmadan yavaÅŸ (medium model ~5-10x realtime)

**4. pyannote.audio**
- **Versiyon:** 3.1 (En son)
- **Model:** Speaker diarization pipeline
- **Lisans:** MIT
- **Token:** Hugging Face (Ã¼cretsiz)

**Pipeline BileÅŸenleri:**
1. **Segmentation:** Ses aktivitesi tespit (VAD - Voice Activity Detection)
2. **Embedding:** Her segment iÃ§in konuÅŸmacÄ± embedding'i Ã§Ä±kar
3. **Clustering:** Embedding'leri grupla (aynÄ± konuÅŸmacÄ±lar)
4. **Resegmentation:** Kesin sÄ±nÄ±rlarÄ± belirle

**Performans:**
- âœ… State-of-the-art doÄŸruluk (DER ~5-10%)
- âœ… Dil-baÄŸÄ±msÄ±z
- âš ï¸ GPU Ã¶neriliyor (CPU'da 5-8x yavaÅŸ)

**5. torch & torchaudio**
- **KullanÄ±m:** pyannote ve Whisper iÃ§in backend
- **CPU vs GPU:**
  - CPU: Her sistemde Ã§alÄ±ÅŸÄ±r
  - GPU: NVIDIA CUDA gerektirir (5-10x hÄ±zlÄ±)

**GPU Kurulumu:**
```bash
# Windows, CUDA 11.8
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121

# macOS (MPS - Metal)
pip install torch torchaudio
```

#### Web ArayÃ¼zÃ¼ (Gelecek)

**6. streamlit**
- **KullanÄ±m:** Web UI (henÃ¼z implement edilmedi)
- **AvantajlarÄ±:**
  - âœ… HÄ±zlÄ± prototyping
  - âœ… Python-only (HTML/CSS/JS bilgisi gerekmez)
  - âœ… Otomatik reactivity

**Planlanan Ã–zellikler:**
- Drag & drop video upload
- Real-time progress tracking
- JSON/TXT indirme
- KonuÅŸmacÄ± renklendirme
- Ä°statistik grafikleri

#### YardÄ±mcÄ± KÃ¼tÃ¼phaneler

**7. loguru**
- **KullanÄ±m:** GeliÅŸmiÅŸ logging
- **Ã–zellikler:**
  - âœ… Kolay syntax: `logger.info()`, `logger.error()`
  - âœ… Renkli konsol Ã§Ä±ktÄ±sÄ±
  - âœ… Otomatik log rotation
  - âœ… Exception tracking

**Ã–rnek:**
```python
from loguru import logger

logger.add(
    "logs/app_{time}.log",
    rotation="1 day",    # Her gÃ¼n yeni dosya
    retention="7 days",  # 7 gÃ¼nden eski loglarÄ± sil
    level="INFO"
)

logger.info("Ä°ÅŸlem baÅŸladÄ±")
logger.success("BaÅŸarÄ±lÄ±!")
logger.error("Hata oluÅŸtu!")
```

**8. python-dotenv**
- **KullanÄ±m:** .env dosyasÄ±ndan environment variables okuma
- **GÃ¼venlik:** Token'larÄ± kodda saklamaktan kaÃ§Ä±nma

**9. tqdm**
- **KullanÄ±m:** Ä°lerleme Ã§ubuklarÄ±
- **Ã–rnek:**
```python
from tqdm import tqdm
for i in tqdm(range(100), desc="Ä°ÅŸleniyor"):
    # Ä°ÅŸlem
```

**10. numpy & pandas**
- **KullanÄ±m:** Veri analizi (ÅŸu an pasif)
- **Potansiyel:** Ä°statistiksel analizler, grafik oluÅŸturma

### 5.2. Sistem Gereksinimleri

**Minimum:**
- Python 3.8+
- 4 GB RAM
- 5 GB disk (modeller iÃ§in)
- FFmpeg kurulu

**Ã–nerilen:**
- Python 3.10+
- 8-16 GB RAM
- NVIDIA GPU (CUDA destekli) - 4GB+ VRAM
- SSD

**Platform DesteÄŸi:**
- âœ… Windows 10/11
- âœ… macOS (M1/M2 MPS desteÄŸi)
- âœ… Linux (Ubuntu, Debian, etc.)

---

## 6. KonfigÃ¼rasyon Sistemi

### 6.1. Environment Variables (.env)

**Dosya YapÄ±sÄ±:**
```bash
# .env (GÄ°T'E EKLENMEMELÄ°!)
HUGGINGFACE_TOKEN=hf_xxxxxxxxxxxxx
WHISPER_MODEL=small
LANGUAGE=tr
AUDIO_SAMPLE_RATE=16000
AUDIO_CHANNELS=1
```

**YÃ¶netim:**
```python
# settings.py
from dotenv import load_dotenv
import os

load_dotenv()  # .env dosyasÄ±nÄ± yÃ¼kle

HUGGINGFACE_TOKEN = os.getenv("HUGGINGFACE_TOKEN", "")
WHISPER_MODEL_SIZE = os.getenv("WHISPER_MODEL", "small")
```

**GÃ¼venlik:**
- âœ… `.env` dosyasÄ± `.gitignore`'da
- âœ… `.env.example` ÅŸablon olarak sunuluyor
- âœ… Token'lar asla kod iÃ§inde hardcoded deÄŸil

### 6.2. KlasÃ¶r YapÄ±sÄ± YÃ¶netimi

**Otomatik OluÅŸturma:**
```python
# settings.py
for directory in [UPLOAD_DIR, OUTPUT_DIR, MODEL_DIR, LOG_DIR]:
    directory.mkdir(exist_ok=True)
```

**exist_ok=True Ã–nemi:**
- KlasÃ¶r varsa hata vermiyor
- KlasÃ¶r yoksa oluÅŸturuyor
- Ä°dempotent (her Ã§alÄ±ÅŸtÄ±rmada gÃ¼venli)

### 6.3. KonfigÃ¼rasyon Best Practices

**âœ… Ä°yi Uygulamalar:**
1. Merkezi settings.py dosyasÄ±
2. Environment variables iÃ§in .env
3. Default deÄŸerler her zaman var
4. Path'ler pathlib.Path ile
5. TÃ¼m ayarlar UPPERCASE (konvansiyon)

**âŒ KÃ¶tÃ¼ Uygulamalar:**
1. ~~Hardcoded paths~~ â†’ pathlib.Path kullan
2. ~~Token'larÄ± kod iÃ§inde~~ â†’ .env'de tut
3. ~~Magic numbers~~ â†’ Sabitler tanÄ±mla
4. ~~Her modÃ¼lde ayrÄ± config~~ â†’ Merkezi yÃ¶netim

---

## 7. GÃ¼venlik ve Best Practices

### 7.1. GÃ¼venlik Ã–nlemleri

#### Token YÃ¶netimi

**âœ… GÃ¼venli:**
```python
# .env
HUGGINGFACE_TOKEN=hf_xxxxx

# .gitignore
.env
.env.local

# settings.py
HUGGINGFACE_TOKEN = os.getenv("HUGGINGFACE_TOKEN", "")
```

**âŒ GÃœVENSÄ°Z:**
```python
# âŒ Asla yapma!
HUGGINGFACE_TOKEN = "hf_xxxxxxxxxxxxx"  # Hardcoded
```

#### Dosya YÃ¼kleme GÃ¼venliÄŸi

**Validasyon Kontrolleri:**
```python
def validate_video_file(video_path):
    # 1. Dosya var mÄ±?
    if not video_path.exists():
        raise FileNotFoundError()

    # 2. Desteklenen format mÄ±?
    if video_path.suffix.lower() not in SUPPORTED_VIDEO_FORMATS:
        raise ValueError("Desteklenmeyen format")

    # 3. Boyut limiti
    file_size_mb = video_path.stat().st_size / (1024 * 1024)
    if file_size_mb > MAX_FILE_SIZE_MB:
        raise ValueError("Dosya Ã§ok bÃ¼yÃ¼k")

    # 4. MIME type kontrolÃ¼ (opsiyonel, gelecek)
    # import magic
    # mime = magic.from_file(str(video_path), mime=True)
    # if mime not in ALLOWED_MIMES:
    #     raise ValueError("GeÃ§ersiz dosya tipi")
```

**DoS (Denial of Service) KorumasÄ±:**
- âœ… MAX_FILE_SIZE_MB limiti (500 MB)
- â³ Rate limiting (web UI'da eklenecek)
- â³ Timeout mekanizmasÄ± (uzun iÅŸlemler iÃ§in)

#### GeÃ§ici Dosya YÃ¶netimi

**Temizlik:**
```python
try:
    audio = extract_audio(video)
    result = process(audio)
finally:
    # settings.TEMP_FILE_CLEANUP = True ise
    if settings.TEMP_FILE_CLEANUP and audio.exists():
        audio.unlink()
```

### 7.2. Code Quality Best Practices

#### Type Hints

**âœ… Ä°yi:**
```python
from pathlib import Path
from typing import Union, Dict, List

def extract_audio(
    video_path: Union[str, Path],
    output_path: Union[str, Path] = None
) -> Path:
    ...
```

**AvantajlarÄ±:**
- IDE autocomplete
- Statik tip kontrolÃ¼ (mypy)
- DokÃ¼mantasyon olarak

#### Docstrings

**Format:** Google Style

```python
def extract_audio_from_video(
    video_path: Union[str, Path],
    output_path: Union[str, Path] = None
) -> Path:
    """
    Video dosyasÄ±ndan ses Ã§Ä±karÄ±r ve WAV formatÄ±nda kaydeder.

    Args:
        video_path: Video dosyasÄ±nÄ±n yolu (str veya Path)
            Ã–rnek: "video.mp4" veya Path("videos/sample.mp4")

        output_path: Ã‡Ä±ktÄ± ses dosyasÄ±nÄ±n yolu (opsiyonel)
            Verilmezse otomatik oluÅŸturulur
            Ã–rnek: "audio.wav"

    Returns:
        Path: OluÅŸturulan ses dosyasÄ±nÄ±n yolu

    Raises:
        FileNotFoundError: Video dosyasÄ± bulunamazsa
        Exception: Video iÅŸleme hatasÄ±

    Ã–rnek KullanÄ±m:
        >>> audio_path = extract_audio_from_video("video.mp4")
        >>> print(audio_path)
        Path('uploads/video_audio.wav')
    """
```

#### Logging Seviyeleri

**KullanÄ±m:**
```python
logger.debug("Video yÃ¼kleniyor...")       # GeliÅŸtirme sÄ±rasÄ±nda
logger.info("Video iÅŸleniyor: video.mp4") # Normal iÅŸlem akÄ±ÅŸÄ±
logger.success("Ses baÅŸarÄ±yla Ã§Ä±karÄ±ldÄ±") # BaÅŸarÄ±lÄ± iÅŸlem
logger.warning("CPU kullanÄ±lÄ±yor...")     # UyarÄ± (hata deÄŸil)
logger.error("Video iÅŸleme hatasÄ±: ...")  # Hata (iÅŸlem devam eder)
logger.critical("Sistem hatasÄ±!")         # Kritik (uygulama durabilir)
```

#### Exception Handling

**Principle:** Fail fast, fail loudly

```python
# âœ… Ä°yi: Spesifik exception'lar
try:
    video = VideoFileClip(video_path)
except FileNotFoundError:
    logger.error("Dosya bulunamadÄ±")
    raise
except PermissionError:
    logger.error("Dosya eriÅŸim izni yok")
    raise
except Exception as e:
    logger.error(f"Beklenmeyen hata: {e}")
    raise

# âŒ KÃ¶tÃ¼: Sessizce geÃ§
try:
    video = VideoFileClip(video_path)
except:
    pass  # Hata yutuldu, debug zor!
```

#### Resource Management

**Context Managers:**
```python
# âœ… Ä°yi: Otomatik temizlik
with open(file_path, 'r') as f:
    data = f.read()
# Dosya otomatik kapanÄ±r

# âŒ KÃ¶tÃ¼: Manuel
f = open(file_path, 'r')
data = f.read()
f.close()  # Unutulabilir!
```

**Video/Audio Cleanup:**
```python
video = VideoFileClip(video_path)
audio = video.audio
try:
    audio.write_audiofile(output_path)
finally:
    audio.close()
    video.close()  # Her durumda kapat
```

### 7.3. Performance Best Practices

#### Lazy Loading

**âœ… Ä°yi:**
```python
class Transcriber:
    def __init__(self):
        self.model = None  # HenÃ¼z yÃ¼klenmedi

    def load_model(self):
        if self.model is None:  # Ä°lk kullanÄ±mda yÃ¼kle
            self.model = whisper.load_model(...)
```

**Avantaj:** Model kullanÄ±lmayacaksa bellekte yer kaplamÄ±yor.

#### Caching

**Model Caching:**
```python
# Whisper modelleri otomatik cache'leniyor
# Ä°lk Ã§alÄ±ÅŸtÄ±rma: Model indirilir (~2 dakika)
# Sonraki: Cache'den yÃ¼klenir (~5 saniye)

# Cache lokasyonu:
# Windows: C:\Users\USERNAME\.cache\whisper\
# Linux/Mac: ~/.cache/whisper/
```

#### Memory Management

**BÃ¼yÃ¼k dosyalar iÃ§in:**
```python
# âŒ KÃ¶tÃ¼: TÃ¼m dosya belleÄŸe
data = open("huge_file.wav", "rb").read()  # OOM riski

# âœ… Ä°yi: Chunk'lar halinde
with open("huge_file.wav", "rb") as f:
    while chunk := f.read(8192):
        process(chunk)
```

---

## 8. Eksik BileÅŸenler ve Sonraki AdÄ±mlar

### 8.1. TamamlanmÄ±ÅŸ BileÅŸenler âœ…

1. **âœ… Video Ä°ÅŸleme ModÃ¼lÃ¼** (video_processor.py)
   - Ses extraction
   - Format dÃ¶nÃ¼ÅŸÃ¼mÃ¼
   - Validasyon

2. **âœ… Speech-to-Text ModÃ¼lÃ¼** (transcriber.py)
   - Whisper entegrasyonu
   - GÃ¼ven skoru hesaplama
   - Ã‡oklu dil desteÄŸi

3. **âœ… Speaker Diarization ModÃ¼lÃ¼** (diarizer.py)
   - pyannote entegrasyonu
   - Ä°statistik hesaplama
   - GPU/CPU desteÄŸi

4. **âœ… Output Formatter** (output_formatter.py)
   - Overlap mantÄ±ÄŸÄ±
   - JSON/Text export
   - Ä°statistik raporlama

5. **âœ… KonfigÃ¼rasyon Sistemi** (settings.py)
   - Environment variables
   - KlasÃ¶r yÃ¶netimi
   - Default ayarlar

### 8.2. Eksik/TamamlanmamÄ±ÅŸ BileÅŸenler â³

#### 1. Ana CLI ProgramÄ± (v_to_t.py)

**Mevcut Durum:**
```python
# Sadece iskelet kod
def main():
    print("Video-to-Text DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼")
    print("Proje kurulum aÅŸamasÄ±nda...")
```

**OlmasÄ± Gereken:**
```python
import argparse
from app.video_processor import extract_audio_from_video
from app.transcriber import Transcriber
from app.diarizer import SpeakerDiarizer
from app.output_formatter import OutputFormatter

def main():
    parser = argparse.ArgumentParser(
        description='Video-to-Text DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼'
    )
    parser.add_argument('video', help='Video dosyasÄ± yolu')
    parser.add_argument('--model', default='small',
                       choices=['tiny', 'small', 'medium', 'large'])
    parser.add_argument('--language', default='tr')
    parser.add_argument('--num-speakers', type=int,
                       help='KonuÅŸmacÄ± sayÄ±sÄ± (opsiyonel)')
    parser.add_argument('--output', help='Ã‡Ä±ktÄ± dosyasÄ± yolu')

    args = parser.parse_args()

    # 1. Ses Ã§Ä±kar
    audio = extract_audio_from_video(args.video)

    # 2. Transcribe et
    transcriber = Transcriber(model_size=args.model,
                             language=args.language)
    transcription = transcriber.transcribe(audio)

    # 3. Diarize et
    diarizer = SpeakerDiarizer()
    diarization = diarizer.diarize(audio,
                                   num_speakers=args.num_speakers)

    # 4. BirleÅŸtir
    result = OutputFormatter.merge_results(
        transcription, diarization,
        video_name=args.video
    )

    # 5. Kaydet
    output_path = args.output or "output.json"
    OutputFormatter.save_to_json(result, output_path)

    print(f"âœ… Ä°ÅŸlem tamamlandÄ±: {output_path}")

if __name__ == "__main__":
    main()
```

**KullanÄ±m:**
```bash
python v_to_t.py video.mp4 --model small --language tr --num-speakers 2
```

#### 2. Web ArayÃ¼zÃ¼ (app/web_interface.py)

**HiÃ§ oluÅŸturulmamÄ±ÅŸ.**

**Planlanan Ã–zellikler:**

```python
# app/web_interface.py
import streamlit as st
from pathlib import Path
import tempfile

st.set_page_config(page_title="Video-to-Text", layout="wide")

st.title("ğŸ¥ Video-to-Text DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼")

# Dosya yÃ¼kleme
uploaded_file = st.file_uploader(
    "Video dosyasÄ± yÃ¼kleyin",
    type=['mp4', 'avi', 'mov', 'mkv']
)

col1, col2 = st.columns(2)
with col1:
    model_size = st.selectbox("Model Boyutu",
                              ['tiny', 'small', 'medium', 'large'])
with col2:
    language = st.selectbox("Dil", ['tr', 'en'])

num_speakers = st.number_input("KonuÅŸmacÄ± SayÄ±sÄ± (opsiyonel)",
                                min_value=0, max_value=10, value=0)

if st.button("ğŸš€ DÃ¶nÃ¼ÅŸtÃ¼r"):
    if uploaded_file:
        # GeÃ§ici dosya kaydet
        with tempfile.NamedTemporaryFile(delete=False,
                                         suffix='.mp4') as tmp:
            tmp.write(uploaded_file.read())
            video_path = tmp.name

        # Progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()

        # Ä°ÅŸlem
        status_text.text("1/4: Ses Ã§Ä±karÄ±lÄ±yor...")
        progress_bar.progress(25)
        audio = extract_audio_from_video(video_path)

        status_text.text("2/4: KonuÅŸma metne Ã§evriliyor...")
        progress_bar.progress(50)
        transcriber = Transcriber(model_size=model_size,
                                 language=language)
        transcription = transcriber.transcribe(audio)

        status_text.text("3/4: KonuÅŸmacÄ±lar ayÄ±rÄ±lÄ±yor...")
        progress_bar.progress(75)
        diarizer = SpeakerDiarizer()
        diarization = diarizer.diarize(audio,
                                      num_speakers=num_speakers or None)

        status_text.text("4/4: SonuÃ§ hazÄ±rlanÄ±yor...")
        progress_bar.progress(90)
        result = OutputFormatter.merge_results(
            transcription, diarization,
            video_name=uploaded_file.name
        )

        progress_bar.progress(100)
        status_text.text("âœ… TamamlandÄ±!")

        # SonuÃ§ gÃ¶ster
        st.success(f"Ä°ÅŸlem baÅŸarÄ±lÄ±! {len(result['speakers'])} konuÅŸmacÄ± tespit edildi.")

        # Timeline
        st.subheader("Zaman Ã‡izelgesi")
        for seg in result['timeline'][:10]:  # Ä°lk 10
            with st.expander(
                f"[{seg['start']:.1f}s - {seg['end']:.1f}s] {seg['speaker']}"
            ):
                st.write(seg['text'])
                st.caption(f"GÃ¼ven: {seg['confidence']:.0%}")

        # Ä°statistikler
        st.subheader("KonuÅŸmacÄ± Ä°statistikleri")
        for speaker, stats in result['speakers'].items():
            col1, col2, col3 = st.columns(3)
            col1.metric(speaker, f"{stats['total_duration']:.1f}s")
            col2.metric("Kelime", stats['total_words'])
            col3.metric("YÃ¼zde", f"%{stats['percentage']}")

        # Ä°ndirme
        st.subheader("Ä°ndir")
        col1, col2 = st.columns(2)

        with col1:
            json_str = json.dumps(result, ensure_ascii=False, indent=2)
            st.download_button(
                "ğŸ“¥ JSON Ä°ndir",
                data=json_str,
                file_name="sonuc.json",
                mime="application/json"
            )

        with col2:
            # Text export
            txt_path = Path(tempfile.mktemp(suffix='.txt'))
            OutputFormatter.export_to_text(result, txt_path)
            with open(txt_path, 'r', encoding='utf-8') as f:
                txt_content = f.read()
            st.download_button(
                "ğŸ“¥ Text Ä°ndir",
                data=txt_content,
                file_name="sonuc.txt",
                mime="text/plain"
            )
```

**Ã‡alÄ±ÅŸtÄ±rma:**
```bash
streamlit run app/web_interface.py
```

#### 3. Logging Sistemi

**Eksik:**
- Merkezi logging konfigÃ¼rasyonu
- Log rotation
- Log seviyeleri ayarÄ±

**Eklenmeli:**

```python
# app/logger.py
from loguru import logger
import sys
from config import settings

# Konsol handler
logger.remove()  # Default'u kaldÄ±r
logger.add(
    sys.stdout,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
    level=settings.LOG_LEVEL,
    colorize=True
)

# Dosya handler
logger.add(
    settings.LOG_DIR / "app_{time}.log",
    rotation=settings.LOG_ROTATION,
    retention=settings.LOG_RETENTION,
    level=settings.LOG_LEVEL,
    encoding="utf-8"
)

# Error log (sadece hatalar)
logger.add(
    settings.LOG_DIR / "errors_{time}.log",
    rotation=settings.LOG_ROTATION,
    retention="30 days",
    level="ERROR",
    encoding="utf-8"
)
```

**KullanÄ±m:**
```python
# Her modÃ¼lde
from app.logger import logger

logger.info("Ä°ÅŸlem baÅŸladÄ±")
```

#### 4. Test Suite

**HiÃ§ test yok!**

**Eklenmeli:**

```python
# tests/test_video_processor.py
import pytest
from pathlib import Path
from app.video_processor import extract_audio_from_video

def test_extract_audio_success():
    video_path = Path("tests/fixtures/sample.mp4")
    audio_path = extract_audio_from_video(video_path)

    assert audio_path.exists()
    assert audio_path.suffix == ".wav"

def test_extract_audio_file_not_found():
    with pytest.raises(FileNotFoundError):
        extract_audio_from_video("nonexistent.mp4")

def test_validate_video_file():
    from app.video_processor import validate_video_file

    # GeÃ§erli format
    assert validate_video_file("test.mp4") == True

    # GeÃ§ersiz format
    with pytest.raises(ValueError):
        validate_video_file("test.txt")
```

**Test KomutlarÄ±:**
```bash
# TÃ¼m testler
pytest

# Coverage raporu
pytest --cov=app --cov-report=html

# Tek test
pytest tests/test_video_processor.py::test_extract_audio_success
```

#### 5. Performans Ä°yileÅŸtirmeleri

**Paralel Ä°ÅŸleme:**
```python
# utils/parallel_processor.py
import concurrent.futures

def process_video_parallel(video_path):
    audio = extract_audio(video_path)

    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
        # Paralel Ã§alÄ±ÅŸtÄ±r
        future_trans = executor.submit(transcribe, audio)
        future_diar = executor.submit(diarize, audio)

        transcription = future_trans.result()
        diarization = future_diar.result()

    return merge_results(transcription, diarization)
```

**Batch Processing:**
```python
def process_multiple_videos(video_paths):
    results = []
    for video in video_paths:
        result = process_video(video)
        results.append(result)
    return results
```

#### 6. DokÃ¼mantasyon

**Eksikler:**
- â³ API dokÃ¼mantasyonu (Sphinx)
- â³ KullanÄ±m Ã¶rnekleri
- â³ Deployment rehberi
- â³ Troubleshooting guide

### 8.3. Ã–ncelikli To-Do Listesi

**Faz 3: CLI ve Web UI (Åu an Ã¶ncelik)**

1. **v_to_t.py CLI implement** (2-3 saat)
   - argparse entegrasyonu
   - Progress indicator
   - Error handling

2. **web_interface.py Streamlit UI** (4-6 saat)
   - Dosya upload
   - Progress tracking
   - SonuÃ§ gÃ¶rÃ¼ntÃ¼leme
   - Ä°ndirme butonlarÄ±

3. **Merkezi logging sistemi** (1-2 saat)
   - app/logger.py oluÅŸturma
   - TÃ¼m modÃ¼llerde kullanÄ±m

**Faz 4: Test ve Kalite (SonrasÄ±)**

4. **Test suite** (8-10 saat)
   - Unit tests
   - Integration tests
   - Fixtures oluÅŸturma

5. **DokÃ¼mantasyon** (4-6 saat)
   - Sphinx setup
   - API docs
   - KullanÄ±m kÄ±lavuzu

**Faz 5: Ä°yileÅŸtirmeler (Opsiyonel)**

6. **Performans optimizasyonu**
   - Paralel iÅŸleme
   - Caching stratejileri
   - Memory optimization

7. **Deployment**
   - Docker containerization
   - Requirements freeze
   - Production config

---

## 9. SonuÃ§ ve DeÄŸerlendirme

### 9.1. Proje GÃ¼Ã§lÃ¼ YÃ¶nleri

1. **âœ… Temiz Mimari**
   - Separation of Concerns
   - Single Responsibility
   - ModÃ¼ler tasarÄ±m

2. **âœ… Ä°yi DokÃ¼mantasyon**
   - DetaylÄ± docstrings
   - Kod iÃ§i yorumlar (TÃ¼rkÃ§e)
   - README.md

3. **âœ… Modern Teknolojiler**
   - State-of-the-art AI modelleri (Whisper, pyannote)
   - Type hints
   - Loguru logging
   - pathlib kullanÄ±mÄ±

4. **âœ… GÃ¼venlik Bilinci**
   - Token'lar .env'de
   - Dosya validasyonu
   - Boyut limitleri

5. **âœ… Error Handling**
   - Try-except bloklarÄ±
   - Resource cleanup
   - Meaningful error messages

### 9.2. Ä°yileÅŸtirilebilir Alanlar

1. **âš ï¸ Test Coverage**
   - HiÃ§ test yok
   - CI/CD pipeline yok

2. **âš ï¸ Performans**
   - Paralel iÅŸleme yok
   - Batch processing yok
   - Progress tracking kÄ±sÄ±tlÄ±

3. **âš ï¸ KullanÄ±labilirlik**
   - CLI henÃ¼z minimal
   - Web UI yok
   - Hata mesajlarÄ± geliÅŸtirilebilir

4. **âš ï¸ Deployment**
   - Docker yok
   - Production config yok
   - Monitoring/logging merkezi deÄŸil

### 9.3. Kod Kalitesi Metrikleri

| Metrik | DeÄŸer | Durum |
|--------|-------|-------|
| Toplam SatÄ±r | ~1,543 | âœ… Orta boyut |
| Docstring Coverage | ~90% | âœ… Ã‡ok iyi |
| Type Hints | ~80% | âœ… Ä°yi |
| Test Coverage | 0% | âŒ Yok |
| Cyclomatic Complexity | DÃ¼ÅŸÃ¼k-Orta | âœ… Basit |
| Code Duplication | Minimal | âœ… DRY |
| Comment Ratio | YÃ¼ksek | âœ… EÄŸitici |

### 9.4. Tavsiyeler

**GeliÅŸtiriciler Ä°Ã§in:**

1. **Ã–ncelik 1:** CLI ve Web UI'yi tamamlayÄ±n (kullanÄ±labilir hale getirin)
2. **Ã–ncelik 2:** Test suite ekleyin (gÃ¼venilirlik)
3. **Ã–ncelik 3:** Performans optimizasyonu (kullanÄ±cÄ± deneyimi)

**Yeni BaÅŸlayanlar Ä°Ã§in:**

1. README.md'yi okuyun
2. requirements.txt'i kurun
3. .env.example â†’ .env yapÄ±n
4. Her modÃ¼lÃ¼n `if __name__ == "__main__"` bÃ¶lÃ¼mÃ¼nÃ¼ Ã§alÄ±ÅŸtÄ±rÄ±n (test)
5. Kod yorumlarÄ±nÄ± okuyun (eÄŸitici)

**KatkÄ±da Bulunacaklar Ä°Ã§in:**

1. Fork + feature branch yapÄ±n
2. Test yazÄ±n (pytest)
3. Docstring ekleyin (Google style)
4. Type hints kullanÄ±n
5. Loguru ile loglayÄ±n
6. Pull request gÃ¶nderin

---

## 10. Kaynaklar ve Referanslar

### KullanÄ±lan KÃ¼tÃ¼phaneler

- **Whisper:** https://github.com/openai/whisper
- **pyannote.audio:** https://github.com/pyannote/pyannote-audio
- **moviepy:** https://zulko.github.io/moviepy/
- **streamlit:** https://streamlit.io/
- **loguru:** https://github.com/Delgan/loguru

### FaydalÄ± DÃ¶kÃ¼manlar

- Whisper model kartÄ±: https://huggingface.co/openai/whisper-large-v3
- pyannote kullanÄ±m: https://huggingface.co/pyannote/speaker-diarization-3.1
- FFmpeg komutlarÄ±: https://ffmpeg.org/documentation.html

### Benzer Projeler

- WhisperX: https://github.com/m-bain/whisperX
- Faster Whisper: https://github.com/guillaumekln/faster-whisper

---

**Analiz TamamlandÄ±!**
**Toplam Dosya SayÄ±sÄ±:** 10 Python dosyasÄ±
**Toplam SatÄ±r:** ~1,543 satÄ±r kod
**Analiz ZamanÄ±:** 30 KasÄ±m 2025
**Versiyon:** Faz 2 (Core Modules Complete)
